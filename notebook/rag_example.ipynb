{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Retrieval-Augmented Generation (RAG) System",
   "id": "de50c9d4e13a4d66"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 1: Parsing & Chunking",
   "id": "3e8e0d4735722b44"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-18T15:57:45.777716Z",
     "start_time": "2025-07-18T15:57:42.364792Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "from docling import chunking\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling_core.transforms.chunker.tokenizer.huggingface import HuggingFaceTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "class Chunker:\n",
    "    def __init__(self, embedding_model: str, max_tokens: int = 1024):\n",
    "        tokenizer = HuggingFaceTokenizer(\n",
    "            tokenizer=AutoTokenizer.from_pretrained(embedding_model),\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        self.__chunker = chunking.HybridChunker(tokenizer=tokenizer, merge_peers=True)\n",
    "\n",
    "    def chunk(self, source: str):\n",
    "        doc = DocumentConverter().convert(source=source).document\n",
    "        chunk_iter = self.__chunker.chunk(dl_doc=doc)\n",
    "        chunks = list(chunk_iter)\n",
    "        chunks_dicts = []\n",
    "        for chunk in chunks:\n",
    "            chunks_dicts.append(\n",
    "                {\n",
    "                    \"content\": chunk.text,\n",
    "                    \"page_number\": chunk.meta.doc_items[0].prov[0].page_no,\n",
    "                    \"pdf_name\": os.path.basename(source),\n",
    "                }\n",
    "            )\n",
    "        return chunks_dicts\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 2: Embedding with SentenceTransformer\n",
   "id": "97da6e646371627c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T15:58:35.146096Z",
     "start_time": "2025-07-18T15:58:34.933377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "class CustomEmbeddings:\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_name: str,\n",
    "            trust_remote_code: bool = True,\n",
    "            device: str = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "            normalize_embeddings: bool = True,\n",
    "    ):\n",
    "        self.model_name = model_name\n",
    "        self.normalize_embeddings = normalize_embeddings\n",
    "        self.model = SentenceTransformer(\n",
    "            model_name,\n",
    "            trust_remote_code=trust_remote_code,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        embeddings = self.model.encode(\n",
    "            texts,\n",
    "            normalize_embeddings=self.normalize_embeddings,\n",
    "            convert_to_tensor=False\n",
    "        )\n",
    "        return embeddings.tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        embedding = self.model.encode(\n",
    "            text,\n",
    "            normalize_embeddings=self.normalize_embeddings,\n",
    "            convert_to_tensor=False\n",
    "        )\n",
    "        return embedding.tolist()\n",
    "\n",
    "    @property\n",
    "    def embedding_dimension(self) -> int:\n",
    "        \"\"\"Get the dimension of the embeddings.\"\"\"\n",
    "        return self.model.get_sentence_embedding_dimension()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "47d639e45d606a2d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 3: Indexing & Semantic Search with LanceDB",
   "id": "25e633cdacfeb39a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T15:59:03.074867Z",
     "start_time": "2025-07-18T15:59:02.954416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "import lancedb\n",
    "from lancedb.table import Table\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "class LanceDB:\n",
    "\n",
    "    def __init__(self,\n",
    "                 vector_storage_path: str = \"./lancedb/vector_storage\",\n",
    "                 table_name: str = \"knowledge_base\"):\n",
    "        db = lancedb.connect(uri=vector_storage_path)\n",
    "        import pyarrow as pa\n",
    "        schema = pa.schema([\n",
    "            pa.field(\"content\", pa.string()),\n",
    "            pa.field(\"page_number\", pa.int32()),\n",
    "            pa.field(\"pdf_name\", pa.string()),\n",
    "            pa.field(\"embeddings\", pa.list_(pa.float32(), 1024)),\n",
    "        ])\n",
    "        try:\n",
    "            db.create_table(table_name, schema=schema)\n",
    "            print(f\"Table {table_name} created successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Table {table_name} already exists. {e}\")\n",
    "        self.__table: Table = db.open_table(name=table_name)\n",
    "\n",
    "    def semantic_search(self, vector_query: list[float], n: int = 10, distance_threshold=0.50) -> DataFrame:\n",
    "        search_results = self.__table.search(vector_query, vector_column_name=\"embeddings\").distance_type(\n",
    "            \"cosine\").limit(n).to_pandas()\n",
    "        print(f\"search_results\\n\\n {search_results}\")\n",
    "        return search_results.loc[search_results[\"_distance\"] <= distance_threshold]\n",
    "\n",
    "    def get_count(self) -> int:\n",
    "        return self.__table.count_rows()\n",
    "\n",
    "    def save(self, df: DataFrame):\n",
    "        self.__table.add(df)\n",
    "        print(f\"total records in lancedb : {self.__table.count_rows()}\")\n",
    "\n",
    "    def create_index(self):\n",
    "        try:\n",
    "            self.__table.create_index(metric=\"cosine\", vector_column_name=\"embeddings\")\n",
    "        except Exception as e:\n",
    "            print(f\"Seems index already exist {e}\")\n"
   ],
   "id": "1d11124bbcd3e940",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 4: Prompt Template\n",
   "id": "8a785232c63e30a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T15:59:39.560556Z",
     "start_time": "2025-07-18T15:59:39.557898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PromptTemplate:\n",
    "    @staticmethod\n",
    "    def build(context: str, question: str, max_token: int = 512) -> str:\n",
    "        prompt = f\"\"\"You are a Climate Science Assistant using IPCC research to explain climate change clearly and compassionately.\n",
    "\n",
    "**Your Approach:**\n",
    "- Use solid IPCC scientific evidence\n",
    "- Explain concepts accessibly for all audiences\n",
    "- Be honest about uncertainties while providing clear guidance\n",
    "- Support responses with specific data and findings\n",
    "- Remain helpful, accurate, and encouraging\n",
    "- **Keep responses under {max_token} tokens**\n",
    "\n",
    "**Available Scientific Context (IPCC 2023 Synthesis Report):**\n",
    "{context}\n",
    "\n",
    "**Question:**\n",
    "{question}\n",
    "\n",
    "**Your Response (max {max_token} tokens):**\n",
    "\n",
    "        \"\"\"\n",
    "        return prompt\n"
   ],
   "id": "776867ebfa80cae9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 5: LLM Inference Using Qwen\n",
   "id": "f3ba46d5d8892c7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T16:00:13.760923Z",
     "start_time": "2025-07-18T16:00:13.756696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "class QwenLLM:\n",
    "\n",
    "    def __init__(self, model_name: str = \"Qwen/Qwen3-1.7B\"):\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "        self.device = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self) -> None:\n",
    "        print(f\"Loading model: {self.model_name}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_name,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "        self.device = self.model.device\n",
    "        print(f\"Model loaded successfully on device: {self.device}\")\n",
    "\n",
    "    def _prepare_messages(self, prompt: str) -> List[Dict[str, str]]:\n",
    "        return [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    def _parse_thinking_content(self, output_ids: List[int]) -> Tuple[str, str]:\n",
    "        try:\n",
    "            # Find the index of </think> token (151668)\n",
    "            index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "        except ValueError:\n",
    "            # If </think> token not found, no thinking content\n",
    "            index = 0\n",
    "        thinking_content = self.tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "        main_content = self.tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "        return thinking_content, main_content\n",
    "\n",
    "    def invoke(self,\n",
    "               prompt: str,\n",
    "               max_new_tokens: int = 1024,\n",
    "               enable_thinking: bool = True,\n",
    "               return_thinking: bool = True,\n",
    "               **generation_kwargs) -> Dict[str, str]:\n",
    "        messages = self._prepare_messages(prompt)\n",
    "        text = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "            enable_thinking=enable_thinking\n",
    "        )\n",
    "        model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.device)\n",
    "        with torch.no_grad():\n",
    "            generated_ids = self.model.generate(\n",
    "                **model_inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                **generation_kwargs\n",
    "            )\n",
    "        output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "        if enable_thinking and return_thinking:\n",
    "            thinking_content, main_content = self._parse_thinking_content(output_ids)\n",
    "            return {\n",
    "                \"response\": main_content,\n",
    "                \"thinking\": thinking_content\n",
    "            }\n",
    "        else:\n",
    "            content = self.tokenizer.decode(output_ids, skip_special_tokens=True).strip(\"\\n\")\n",
    "            return {\n",
    "                \"response\": content,\n",
    "                \"thinking\": \"\"\n",
    "            }\n"
   ],
   "id": "78a28d9f81350d81",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 6: Putting It All Together\n",
   "id": "6ea7f4c205722ad5"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-18T16:00:41.876911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src.chunker.chunker import Chunker\n",
    "from src.embedding.custom_embedding import CustomEmbeddings\n",
    "from src.llm.qwen_llm import QwenLLM\n",
    "from src.prompt.prompt_template import PromptTemplate\n",
    "from src.storage.lancedb import LanceDB\n",
    "\n",
    "pdf_data = \"https://www.ipcc.ch/report/ar6/syr/downloads/report/IPCC_AR6_SYR_LongerReport.pdf\"\n",
    "\n",
    "EMBEDDING_MODEL = \"BAAI/bge-m3\"\n",
    "LLM_MODEL = \"Qwen/Qwen3-1.7B\"\n",
    "\n",
    "\n",
    "# initialize the embedding model\n",
    "embeddings = CustomEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "# initialize the LLM\n",
    "llm = QwenLLM(model_name=LLM_MODEL)\n",
    "\n",
    "# initialize the Chunker\n",
    "chunker = Chunker(embedding_model=EMBEDDING_MODEL)\n",
    "\n",
    "# initialize the Vector DB\n",
    "lancedb = LanceDB(table_name=\"rag_table\")\n",
    "# Run document Indexing\n",
    "print(\"Start Chunking ....\")\n",
    "documents = chunker.chunk(pdf_data)\n",
    "print(\"Chunking done....\")\n",
    "df = pd.DataFrame(documents, columns=[\"content\", \"page_number\", \"pdf_name\"])\n",
    "print(\"Start Embedding ....\")\n",
    "df[\"embeddings\"] = df[\"content\"].apply(embeddings.embed_query)\n",
    "print(\"Embedding  done....\")\n",
    "print(df)\n",
    "print(\"Start saving ....\")\n",
    "lancedb.save(df)\n",
    "\n",
    "# RAG\n",
    "query = \"How is climate change affecting biodiversity?\"\n",
    "\n",
    "vector_query = embeddings.embed_query(query)\n",
    "result_df = lancedb.semantic_search(vector_query=vector_query, n=2)\n",
    "context = \"\\n\\n\".join(result_df[\"content\"].tolist())\n",
    "formatted_prompt = PromptTemplate.build(context=context, question=query)\n",
    "print(\"\\nFormatted Prompt:\" + \"\\n\" + formatted_prompt)\n",
    "final_response = llm.invoke(formatted_prompt, enable_thinking=True, return_thinking=True)\n",
    "print(\"\\nFinal RAG Response:\")\n",
    "print(final_response[\"response\"])\n"
   ],
   "id": "b817a1f699870e1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: Qwen/Qwen3-1.7B\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7bacab6be69b4f62bafb86e8cfcdaa8c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully on device: mps:0\n",
      "Table rag_table created successfully.\n",
      "Start Chunking ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satendra/open-source/simple-rag-example/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/satendra/open-source/simple-rag-example/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking done....\n",
      "Start Embedding ....\n",
      "Embedding  done....\n",
      "                                               content  page_number  \\\n",
      "0                                                   35            1   \n",
      "1                                                   37            3   \n",
      "2    This Synthesis Report (SYR) of the IPCC Sixth ...            4   \n",
      "3    - 59 The three Special Reports are : Global Wa...            4   \n",
      "4    GHG emissions\\nFigure 1.1: The Synthesis Repor...            5   \n",
      "..                                                 ...          ...   \n",
      "140  Actual yearly flows compared to average annual...           79   \n",
      "141  Enhancing technology innovation systems can pr...           79   \n",
      "142  International cooperation on innovation works ...           80   \n",
      "143  The feasibility, effectiveness and benefits of...           80   \n",
      "144  Mitigation  and  adaptation  when  implemented...           80   \n",
      "\n",
      "                          pdf_name  \\\n",
      "0    IPCC_AR6_SYR_LongerReport.pdf   \n",
      "1    IPCC_AR6_SYR_LongerReport.pdf   \n",
      "2    IPCC_AR6_SYR_LongerReport.pdf   \n",
      "3    IPCC_AR6_SYR_LongerReport.pdf   \n",
      "4    IPCC_AR6_SYR_LongerReport.pdf   \n",
      "..                             ...   \n",
      "140  IPCC_AR6_SYR_LongerReport.pdf   \n",
      "141  IPCC_AR6_SYR_LongerReport.pdf   \n",
      "142  IPCC_AR6_SYR_LongerReport.pdf   \n",
      "143  IPCC_AR6_SYR_LongerReport.pdf   \n",
      "144  IPCC_AR6_SYR_LongerReport.pdf   \n",
      "\n",
      "                                            embeddings  \n",
      "0    [-0.008668040856719017, 0.011863724328577518, ...  \n",
      "1    [-0.043995607644319534, 0.03700130805373192, -...  \n",
      "2    [0.0039987945929169655, 0.025768674910068512, ...  \n",
      "3    [-0.02050931565463543, 0.02267467975616455, -0...  \n",
      "4    [-0.0016337892739102244, 0.005424432456493378,...  \n",
      "..                                                 ...  \n",
      "140  [-0.06887567043304443, -0.002916219411417842, ...  \n",
      "141  [-0.08090069890022278, 0.014329729601740837, -...  \n",
      "142  [-0.07203900814056396, 0.02859506942331791, -0...  \n",
      "143  [-0.08832331746816635, 0.012446340173482895, -...  \n",
      "144  [-0.06169478967785835, -0.0050775338895618916,...  \n",
      "\n",
      "[145 rows x 4 columns]\n",
      "Start saving ....\n",
      "total records in lancedb : 145\n",
      "search_results\n",
      "\n",
      "                                              content  page_number  \\\n",
      "0  Climate change has caused substantial damages,...           12   \n",
      "1  Climate  change  has  reduced  food  security ...           16   \n",
      "\n",
      "                        pdf_name  \\\n",
      "0  IPCC_AR6_SYR_LongerReport.pdf   \n",
      "1  IPCC_AR6_SYR_LongerReport.pdf   \n",
      "\n",
      "                                          embeddings  _distance  \n",
      "0  [-0.044928055, 0.0017286836, -0.06321303, -0.0...   0.367766  \n",
      "1  [-0.02609434, 0.045236155, -0.048266977, -0.00...   0.372714  \n",
      "\n",
      "Formatted Prompt:\n",
      "You are a Climate Science Assistant using IPCC research to explain climate change clearly and compassionately.\n",
      "\n",
      "**Your Approach:**\n",
      "- Use solid IPCC scientific evidence\n",
      "- Explain concepts accessibly for all audiences\n",
      "- Be honest about uncertainties while providing clear guidance\n",
      "- Support responses with specific data and findings\n",
      "- Remain helpful, accurate, and encouraging\n",
      "- **Keep responses under 512 tokens**\n",
      "\n",
      "**Available Scientific Context (IPCC 2023 Synthesis Report):**\n",
      "Climate change has caused substantial damages, and increasingly irreversible 75 losses,  in  terrestrial,  freshwater,  cryospheric  and coastal and open ocean ecosystems ( high confidence ). The extent and magnitude of climate change impacts are larger than estimated in previous assessments ( high confidence ) .  Approximately half of the species assessed globally have shifted polewards or, on land, also to higher elevations ( very high confidence ). Biological responses including changes in geographic placement and shifting seasonal timing are often not sufficient to cope with recent climate change ( very high confidence ). Hundreds of local losses of species have been driven by increases in the magnitude of heat extremes ( high confidence ) and mass mortality events  on  land  and  in  the  ocean  ( very  high  confidence ).  Impacts  on some ecosystems are approaching irreversibility  such  as  the  impacts of  hydrological  changes  resulting  from  the  retreat  of  glaciers,  or  the changes in some mountain ( medium confidence ) and Arctic ecosystems driven  by  permafrost  thaw  ( high  confidence ).  Impacts  in  ecosystems from slow-onset processes such as ocean acidification, sea level rise or  regional  decreases  in  precipitation  have  also  been  attributed  to human-caused  climate  change  ( high  confidence ).  Climate  change has contributed to desertification and exacerbated land degradation, particularly  in  low  lying  coastal  areas,  river  deltas,  drylands  and  in permafrost areas ( high confidence ). Nearly 50% of coastal wetlands have been lost over the last 100 years, as a result of the combined effects  of  localised  human  pressures,  sea  level  rise,  warming and extreme climate events ( high confidence ). { WGII SPM B.1.1, WGII SPM B.1.2, WGII Figure SPM.2.A, WGII TS.B.1; SRCCL SPM A.1.5, SRCCL SPM A.2, SRCCL SPM A.2.6, SRCCL Figure SPM.1; SROCC SPM A.6.1, SROCC SPM, A.6.4, SROCC SPM A.7 }\n",
      "74 'Main driver' means responsible for more than 50% of the change. { WGI SPM footnote 12 }\n",
      "75\n",
      "See Annex I: Glossary.\n",
      "Table 2.1: Assessment of observed changes in large-scale indicators of mean climate across climate system components, and their attribution to human influence. The colour coding indicates the assessed confidence in / likelihood 76 of the observed change and the human contribution as a driver or main driver (specified in that case) where available (see colour key). Otherwise, explanatory text is provided. { WGI Table TS.1 }\n",
      "Observed change\n",
      "Human contribution\n",
      "\n",
      "Climate  change  has  reduced  food  security  and  affected  water security due to warming, changing precipitation patterns, reduction and loss of cryospheric elements, and greater frequency and  intensity  of  climatic  extremes,  thereby  hindering  efforts  to meet Sustainable Development Goals ( high confidence ). Although overall agricultural productivity has increased, climate change has slowed this growth in agricultural productivity over the past 50 years globally ( medium confidence ),  with  related  negative  crop  yield  impacts  mainly recorded in mid- and low latitude regions, and some positive impacts in  some  high  latitude  regions  ( high  confidence ).  Ocean  warming  in the  20th  century  and  beyond  has  contributed  to  an  overall  decrease in  maximum  catch  potential  ( medium  confidence ),  compounding  the impacts from overfishing for some fish stocks ( high confidence ). Ocean warming and ocean acidification have adversely affected food production from shellfish aquaculture and fisheries in some oceanic regions ( high confidence ). Current levels of global  warming  are  associated  with moderate risks  from  increased  dryland  water  scarcity  ( high  confidence ). Roughly half of the world's population currently experiences severe water scarcity for at least some part of the year due to a combination of climatic and non-climatic drivers ( medium confidence ) (Figure 2.3). Unsustainable agricultural  expansion,  driven  in  part  by  unbalanced  diets 77 ,  increases ecosystem  and  human  vulnerability  and  leads  to  competition  for  land and/or water resources ( high confidence ). Increasing weather and climate extreme events have exposed millions of people to acute food insecurity 78 and reduced water security, with the largest impacts observed in many locations and/or communities in Africa, Asia, Central and South America, LDCs,  Small  Islands  and  the Arctic,  and  for  small-scale  food  producers, low-income households and Indigenous Peoples globally ( high confidence ). { WGII SPM B.1.3, WGII SPM.B.2.3, WGII Figure SPM.2, WGII TS B.2.3, WGII TS Figure TS. 6; SRCCL SPM A.2.8, SRCCL SPM A.5.3; SROCC SPM A.5.4., SROCC SPM A.7.1, SROCC SPM A.8.1, SROCC Figure SPM.2 }\n",
      "In urban settings, climate change has caused adverse impacts on human health, livelihoods and key infrastructure ( high confidence ). Hot  extremes  including  heatwaves  have  intensified  in  cities  ( high confidence ),  where  they  have  also  worsened  air  pollution  events ( medium  confidence ) and  limited  functioning  of  key  infrastructure ( high confidence ).  Urban infrastructure, including transportation, water, sanitation  and  energy  systems  have  been  compromised  by  extreme and slow-onset events 79 ,  with resulting economic losses, disruptions of services and impacts to well-being ( high confidence ). Observed impacts are concentrated amongst economically and socially marginalised urban residents,  e.g.,  those  living  in  informal  settlements ( high  confidence ). Cities  intensify  human-caused  warming  locally  ( very  high  confidence ), while urbanisation also increases mean and heavy precipitation over and/or downwind of cities ( medium confidence )  and resulting runoff intensity ( high confidence ).  { WGI SPM C.2.6; WGII SPM B.1.5, WGII Figure TS.9, WGII 6 ES }\n",
      "Climate change has adversely affected human physical health globally and mental health in assessed regions ( very high confidence ), and is contributing to humanitarian crises where climate hazards interact with high vulnerability ( high confidence ). In all regions increases in extreme  heat  events  have  resulted  in  human  mortality  and  morbidity ( very high confidence ). The occurrence of climate-related food-borne and water-borne diseases has increased ( very high confidence ). The incidence of  vector-borne  diseases  has  increased  from  range  expansion  and/or increased reproduction of disease vectors ( high confidence ) . Animal and human diseases, including zoonoses, are emerging in new areas ( high confidence ).  In  assessed  regions,  some  mental  health  challenges  are associated with increasing temperatures ( high confidence ), trauma from extreme events ( very high confidence ), and loss of livelihoods and culture\n",
      "\n",
      "**Question:**\n",
      "How is climate change affecting biodiversity?\n",
      "\n",
      "**Your Response (max 512 tokens):**\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3170f7fb93969a55"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
